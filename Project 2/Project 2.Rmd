---
title: "Project 2"
author: "Anna Brown, Rishika Deshmukh, and Ada Zhang"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: html_document
---

```{r}
# Load necessary libraries
library(stringr)
library(dplyr)
library(ggplot2)
library(syuzhet)
```

```{r}
# Step 1: Import and Split Data
# Specify the GitHub raw URL
github_url <- "https://github.com/annab0503/DS4002/blob/main/Project%202/Skilled%20Worker%20Visas.txt?raw=true"

# Read the content of the file from GitHub
content <- readLines(github_url, warn = FALSE)

# Combine all lines into a single text string
text <- paste(content, collapse = "\n")

# Split the text by "End of Document"
documents <- str_split(text, "End of Document", simplify = FALSE)[[1]]

# Write each document to a separate file
for (i in seq_along(documents)) {
  doc_path <- paste0("Document_", i, ".txt")
  writeLines(str_trim(documents[i]), con = doc_path)
  cat("Document saved:", doc_path, "\n")
}
```
```{r}
# Specify the path to the first document
doc_path <- "Document_5.txt"

# Read the content of the document
doc_content <- readLines(doc_path)

# Print the content to the console
cat(doc_content, sep = "\n")
```

```{r}
# Step 2: Load Split Documents
# List all document files in the working directory
doc_files <- list.files(pattern = "Document_\\d+\\.txt")

# Read all documents into a list
documents <- lapply(doc_files, readLines)

# Combine each document's content into a single text string
documents <- lapply(documents, paste, collapse = " ")

# Create a data frame for analysis
doc_data <- data.frame(
  Document = doc_files,
  Text = unlist(documents),
  stringsAsFactors = FALSE
)
```

```{r}
# Step 3: Extract Dates from the Text
extract_date <- function(text) {
  # Define a regex pattern for "Month Day, Year" format
  date_pattern <- "\\b(January|February|March|April|May|June|July|August|September|October|November|December) \\d{1,2}, \\d{4}\\b"
  
  # Search for the date using the regex
  date <- str_extract(text, date_pattern)
  
  # If no match, log a message
  if (is.na(date)) { 
    cat("Date extraction failed for document:", substr(text, 1, 100), "...\n") 
  }
  
  return(date)
}

# Apply the function to extract dates for all documents
doc_data$Date <- sapply(doc_data$Text, extract_date)

# Convert the dates to Date type
doc_data$Date <- as.Date(doc_data$Date, format = "%B %d, %Y")

# Extract the year from the Date
doc_data$Year <- format(doc_data$Date, "%Y")
```
```{r}
# Display a preview of the dataset
head(doc_data[, c("Document", "Date", "Year")])
```

```{r}
# Step 4: Perform Sentiment Analysis
# Calculate sentiment scores for each document
doc_data$Sentiment <- sapply(doc_data$Text, function(text) {
  sentiment <- get_sentiment(text, method = "bing")
  mean(sentiment)  # Average sentiment score for the document
})
```

```{r}
# Step 5: Group by Year and Analyze
# Group by year and calculate average sentiment per year
sentiment_by_year <- doc_data %>%
  group_by(Year) %>%
  summarise(AverageSentiment = mean(Sentiment, na.rm = TRUE))
```

```{r}
# Step 6: Visualize Sentiment Over Time
ggplot(sentiment_by_year, aes(x = as.numeric(Year), y = AverageSentiment)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Sentiment Toward Visas Over Time",
    x = "Year",
    y = "Average Sentiment Score"
  ) +
  theme_minimal()
```

```{r}
# Step 7: Validate Results
# View extracted dates, sentiment scores, and text snippets
head(doc_data[, c("Document", "Date", "Sentiment")])

# Print average sentiment by year
print(sentiment_by_year)
```