---
title: "Project 2"
author: "Anna Brown, Rishika Deshmukh, and Ada Zhang"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
output: 
  html_document:
    toc: true        # Enable the Table of Contents
    toc_depth: 3     # Set the depth of headings included in the TOC
    toc_float: true  # Enable floating TOC (keeps TOC fixed as you scroll)
    code_folding: none
    self_contained: false
    css: "styles.css"  # Link to an external stylesheet
---

```{r echo=FALSE, warning=FALSE, message=FALSE, results="hide"}
# Function to check and install missing packages
install_if_missing <- function(package) {
  if (!require(package, character.only = TRUE)) {
    install.packages(package, dependencies = TRUE)
    library(package, character.only = TRUE)
  }
}

# List of required packages
packages <- c(
  "countrycode", "dplyr", "DT", "ggplot2", "gridExtra", "leaflet", 
  "maps", "patchwork", "readr", "rworldmap", "showtext", 
  "sp", "tidyverse"
)

# Ensure all packages are installed and loaded
lapply(packages, install_if_missing)

# Load libraries explicitly
library(countrycode)
library(dplyr)
library(DT)
library(ggplot2)
library(gridExtra)
library(leaflet)
library(maps)
library(patchwork)
library(readr)
library(rworldmap)
library(showtext)
library(sp)
library(tidyverse)

# Set the file path
url <- "https://raw.githubusercontent.com/annab0503/DS4002/main/Project%201/Analysis%20Data/analysis_data.csv"

# Read the CSV file from the URL
analysis_data <- read_csv(url)

# Enable the showtext package
showtext_auto()

# Add Google Fonts
font_add_google("Bodoni Moda", "bodoni_moda")  # Alias: bodoni_moda
font_add_google("Montserrat", "montserrat")     # Alias: montserrat
```

# **Introduction**
This project aims to analyze the tone of articles over a significant period by scrutinizing key words in datasets of articles published by The New York Times. The focus period spans from January 1, 1997, to December 31, 2022, a timeframe that captures several legislative and economic shifts influencing U.S. work visa programs.

A pivotal aspect of our analysis involves exploring the correlation between the volume of articles and the sentiment conveyed within them. Specifically, we aim to determine whether an increase in the quantity of articles about U.S. work visa programs published by The New York Times correlates with a more negative portrayal of these topics. This question is significant as it can indicate whether media coverage tends to become more negative as the frequency of articles on a subject increases, potentially reflecting broader public and political sentiments during periods of intensified discussion.

# **Background**

## Skilled Labor Visas  

The **H-1B visa** is the most prominent skilled labor visa, allowing U.S. employers to hire highly skilled foreign professionals for specialty occupations requiring advanced knowledge and at least a bachelor’s degree or its equivalent. Over the years, the H-1B program has been influenced by economic and political factors. For instance, in 1998, high-tech industry lobbying led to proposals to increase the H-1B visa cap, citing a significant unmet demand for skilled workers. In response, the American Competitiveness in the 21st Century Act temporarily raised the cap to 195,000 between 2001 and 2003, before reverting to 65,000 in 2004. The 2008 recession brought further scrutiny, with Congress targeting the program to protect domestic jobs, resulting in a decline in filed petitions. These fluctuations underscore the program’s sensitivity to broader economic conditions and labor market demands.  


## Economic Perspectives on Foreign Workers

Economic discussions about foreign workers revolve around their contributions to growth and innovation as well as concerns about their impact on the domestic labor market. Proponents argue that foreign workers fill critical labor shortages, enhance innovation, and sustain industries with fluctuating labor demands. For example, H-1B visa holders are often associated with technological advancements, patents, and entrepreneurial activities that drive competitiveness. 

Critics, however, caution against potential wage suppression and increased competition for domestic workers, emphasizing the need for careful policy design to ensure equitable benefits. This research delves into these dynamics, examining how U.S. visa policies reflect broader economic priorities and labor market realities while balancing domestic interests with international interdependence.

# **Methodology**

## Data Sources

**Data Source Introduction**

Our project draws curated datasets of articles published by The New York Times between January 1, 1997, and December 31, 2022, focusing on U.S. work visa programs. These datasets highlights coverage of skilled work visas (H-1B), providing valuable insights into labor market dynamics and immigration policies over the past 25 years.

To construct the datasets, our team utilized **Nexis Uni** to filter and extract relevant articles.Our team applied the following parameters:


| Parameter       | Description                                          |
|-----------------|------------------------------------------------------|
| Keywords        | "U.S visa", "H1-B"                 |
| Source Type     | Newspapers                                           |
| Source Location | North America, United States                         |
| Language        | English                                              |
| Timeline        | January 1, 1997 – December 31, 2022                  |
| Source Name     | The New York Times                                   |



The filtered articles were categorized by the H-1B visa type and saved into a text file based on their date of publication. This  approach allows for easier analysis of trends and policy discussions within each category over the years. 

# **Exploratory Analysis**
```{r echo=FALSE}
if (!require(tidyverse)) install.packages("tidyverse")
if (!require(stringr)) install.packages("stringr")
library(tidyverse)
library(stringr)

main <- function() {
  # Reading the entire text file
  text <- readLines("Skilled Worker Visas.txt", warn = FALSE)
  
  # Combining lines back into a single string for proper regex handling
  text_combined <- paste(text, collapse="\n")
  
  # Using regex to split articles on Load-Date; ensure Load-Date is kept with the article
  articles <- str_split(text_combined, "(?=Load-Date:)", n = Inf, simplify = FALSE)[[1]]
  
  # Extract dates and contents by filtering lines containing 'Load-Date'
  dates <- str_extract(articles, "Load-Date:\\s+[A-Za-z]+\\s+\\d{1,2},\\s+\\d{4}")
  contents <- str_replace(articles, "Load-Date:\\s+[A-Za-z]+\\s+\\d{1,2},\\s+\\d{4}", "")
  
  # Count all articles
  total_article_count <- length(contents)
  print(paste("Total number of articles:", total_article_count))
  
  # Count occurrences of "not"
  total_not_count <- sum(str_count(contents, regex("\\bnot\\b", ignore_case = TRUE)))
  print(paste("Total occurrences of 'not':", total_not_count))
  
  # Extract years from dates for further analysis
  years <- str_extract(dates, "\\d{4}")
  
  # Count articles per year
  year_counts <- table(years)
  
  # Plot article count by year using base plotting
  plot(year_counts, type = "o", main = "Articles per Year", xlab = "Year", ylab = "Number of Articles")
  
  # Analyze occurrences of 'not' by year
  not_counts_by_year <- map2(contents, years, ~ str_count(.x, "\\bnot\\b")) %>% unlist() %>% tibble(year = years, count = .) %>%
    group_by(year) %>% summarise(total_count = sum(count))
  
  # Plot occurrences of 'not' by year using ggplot2
  ggplot(not_counts_by_year, aes(x = year, y = total_count)) +
    geom_col() +
    labs(title = "'not' occurrences per year", x = "Year", y = "Occurrences") +
    theme(axis.text.x = element_text(size = 8))  # Adjusting x-axis label size
}

# Call the main function
main()
```

# **Conclusion**
